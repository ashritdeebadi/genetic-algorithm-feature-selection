{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df_via_individual(individual, train_set, test_set):\n",
    "    '''This function parses the train and test set via the individual\n",
    "    passed. The individual is comprised of a list of len(train_set)\n",
    "    that contains either 0 or 1. 0 or 1 corresponds to whether \n",
    "    that specific column should be used.\n",
    "    \n",
    "    Args:\n",
    "        individual (list(int)): The specific individual thats a list comprised of 1s or 0s\n",
    "        train_set (pd.DataFrame): The dataframe containg the test set\n",
    "        test_set (pd.DataFrame): The dataframe contain the train set\n",
    "    Returns:\n",
    "        (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame): The parsed X_train and X_test\n",
    "    '''\n",
    "    \n",
    "    bool_individual = list(map(bool, individual))\n",
    "    bool_df = pd.DataFrame({'a': bool_individual})\n",
    "    \n",
    "    X_train, y_train = train_set\n",
    "    X_test, y_test = test_set\n",
    "    \n",
    "    X_train = X_train[X_train.columns[bool_individual]]\n",
    "    X_test = X_test[X_test.columns[bool_individual]]\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def calculate_correlation(arr):\n",
    "    '''Function takes the resulting split done by the train_test_split\n",
    "    function and converts it to a pandas DataFrame and then returns \n",
    "    the sum of the sum of the correlation generated by the corr function.\n",
    "    \n",
    "    Args:\n",
    "        arr (np.array(...)): The specific 'X_train' generated by the \n",
    "                             train_test_split function\n",
    "                             \n",
    "    Returns:\n",
    "        float: The resulting correlation calculation\n",
    "    \n",
    "    '''\n",
    "    df = pd.DataFrame(arr)\n",
    "    correlation = df.corr().sum().sum()\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "\n",
    "def load_data(files=['BRAF_train_moe_class.csv', 'BRAF_test_moe_class.csv'], drop = True):\n",
    "    '''Loads the data from the specific two files given \n",
    "    and then concatenates the two to a single DataFrame.\n",
    "    The function also drops the specific rows that contain\n",
    "    rows as well as converting the data format to float\n",
    "    \n",
    "    Args:\n",
    "        files (list(str))(optional): The specific file list of csvs to parse\n",
    "        drop (bool): Whether or not to use the files with the dropped column\n",
    "                     this column will then have to be parsed and coverted to a \n",
    "                     format that works with the calculations (int/ float)\n",
    "                     \n",
    "    Returns:\n",
    "        pd.DataFrame: The resulting DataFrame from the format change\n",
    "    '''\n",
    "    \n",
    "    if drop:\n",
    "        train_df = pd.read_csv(files[0]).drop('PUBCHEM_COORDINATE_TYPE', axis=1)\n",
    "        test_df = pd.read_csv(files[1]).drop('PUBCHEM_COORDINATE_TYPE', axis=1)\n",
    "    else:\n",
    "        train_df = pd.read_csv(files[0])\n",
    "        test_df = pd.read_csv(files[1])\n",
    "        \n",
    "    df = pd.concat(objs = [train_df, test_df], join = 'inner')\n",
    "    df = df.dropna(axis = 0)\n",
    "    df = df.astype(float)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_individual(X_train):\n",
    "    '''Takes the X_train dataset generated by the \n",
    "    train_test_split and returns a list of integers that represent\n",
    "    boolean values via either 0 or 1. \n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The specific X_train generated by \n",
    "                                the train_test_split function. \n",
    "                                \n",
    "    Returns:\n",
    "        list(int): The specific individual generated by the building a\n",
    "                   list of integers are either 1 or 0\n",
    "                   \n",
    "    Example:\n",
    "        >>> generate_individual(X_train)\n",
    "        [ 1, 0, 1, 1, 1, ...]'''\n",
    "    return [random.randint(0, 1) for x in range(len(X_train.columns))]\n",
    "\n",
    "\n",
    "def fitness(individual, train_set, test_set):\n",
    "    \"\"\"Function that outputs the error rate given a train and \n",
    "    test set.\n",
    "    \n",
    "    The function takes an individual, a train set, and a test \n",
    "    set. The individual is comprised of a list of len(train_set)\n",
    "    that contains either 0 or 1. 0 or 1 corresponds to whether \n",
    "    that specific column should be used. The train set and test \n",
    "    set are used to fit and predict the values in the test set\n",
    "    \n",
    "    Args:\n",
    "        individual (list(int)): The specific individual thats a list comprised of 1s or 0s\n",
    "        train_set (pd.DataFrame): The dataframe containg the test set\n",
    "        test_set (pd.DataFrame): The dataframe contain the train set\n",
    "        \n",
    "    Returns:\n",
    "        double: The error rate give the columns passed by the individual\n",
    "        \n",
    "    Example:\n",
    "        >>> individual = [random.randint(0, 1) for x in len(X_train.columns)]\n",
    "        >>> fitness(individual, (X_train, y_train), (X_test, y_test))\n",
    "        0.30\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = parse_df_via_individual(individual, train_set, test_set)\n",
    "    \n",
    "    if len(X_train.columns) == 0:    \n",
    "        return 1.0\n",
    "    \n",
    "    X_train, X_test = scale(X_train), scale(X_test)\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    error = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "    total_correlation = calculate_correlation(X_train)\n",
    "    \n",
    "    return error * total_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "y = df['class']\n",
    "X = df.drop(['class'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "result = []\n",
    "for _ in range(200):\n",
    "    individual = generate_individual(X_train)\n",
    "    resulting_calculation = fitness(individual, (X_train, y_train), (X_test, y_test))\n",
    "    result.append(resulting_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

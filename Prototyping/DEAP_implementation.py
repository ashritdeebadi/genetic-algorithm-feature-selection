
import random

from deap import base
from deap import creator
from deap import tools
from deap import algorithms
from sklearn import svm
from sklearn.metrics import mean_squared_error
from sklearn import model_selection
import random
import pandas as pd
import numpy
import statistics 
pd.options.display.max_rows = 999


df = load_data()

y = df['class']
    
X = df.drop(['class'], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

'''
train_set = pd.read_csv('BRAF_train_moe_class.csv').drop('PUBCHEM_COORDINATE_TYPE', axis=1)
test_set = pd.read_csv('BRAF_test_moe_class.csv').drop('PUBCHEM_COORDINATE_TYPE', axis=1)

train_set = train_set.dropna(axis=0)
test_set = test_set.dropna(axis=0)

#y_train = train_set['class']
X_train = train_set.drop(['class'], axis=1)

#y_test = test_set['class']
#X_test = test_set.drop(['class'], axis=1)



#IND_size = len(X_train)
#print(city_dist)

'''

toolbox = base.Toolbox()

creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)
ind = [random.randint(0, 1) for x in range(len(X_train.columns))]

toolbox.register("indices", numpy.random.permutation, ind)
toolbox.register("individual", tools.initIterate, creator.Individual,toolbox.indices)
toolbox.register("population", tools.initRepeat, list,toolbox.individual)



def parse_df_via_individual(individual, train_set, test_set):
    '''This function parses the train and test set via the individual
    passed. The individual is comprised of a list of len(train_set)
    that contains either 0 or 1. 0 or 1 corresponds to whether 
    that specific column should be used.
    
    Args:
        individual (list(int)): The specific individual thats a list comprised of 1s or 0s
        train_set (pd.DataFrame): The dataframe containg the test set
        test_set (pd.DataFrame): The dataframe contain the train set
    Returns:
        (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame): The parsed X_train and X_test
    '''
    
    bool_individual = list(map(bool, individual))
    bool_df = pd.DataFrame({'a': bool_individual})
    
    X_train, y_train = train_set
    X_test, y_test = test_set
    
    X_train = X_train[X_train.columns[bool_individual]]
    X_test = X_test[X_test.columns[bool_individual]]
    
    return (X_train, y_train, X_test, y_test)


def calculate_correlation(arr):
    '''Function takes the resulting split done by the train_test_split
    function and converts it to a pandas DataFrame and then returns 
    the sum of the sum of the correlation generated by the corr function.
    
    Args:
        arr (np.array(...)): The specific 'X_train' generated by the 
                             train_test_split function
                             
    Returns:
        float: The resulting correlation calculation
    
    '''
    df = pd.DataFrame(arr)
    correlation = df.corr().sum().sum()
    
    return correlation


def load_data(files=['BRAF_train_moe_class.csv', 'BRAF_test_moe_class.csv'], drop = True):
    '''Loads the data from the specific two files given 
    and then concatenates the two to a single DataFrame.
    The function also drops the specific rows that contain
    rows as well as converting the data format to float
    
    Args:
        files (list(str))(optional): The specific file list of csvs to parse
        drop (bool): Whether or not to use the files with the dropped column
                     this column will then have to be parsed and coverted to a 
                     format that works with the calculations (int/ float)
                     
    Returns:
        pd.DataFrame: The resulting DataFrame from the format change
    '''
    
    if drop:
        train_df = pd.read_csv(files[0]).drop('PUBCHEM_COORDINATE_TYPE', axis=1)
        test_df = pd.read_csv(files[1]).drop('PUBCHEM_COORDINATE_TYPE', axis=1)
    else:
        train_df = pd.read_csv(files[0])
        test_df = pd.read_csv(files[1])
        
    df = pd.concat(objs = [train_df, test_df], join = 'inner')
    df = df.dropna(axis = 0)
    df = df.astype(float)
    
    return df


def generate_individual(X_train):
    '''Takes the X_train dataset generated by the 
    train_test_split and returns a list of integers that represent
    boolean values via either 0 or 1. 
    
    Args:
        X_train (pd.DataFrame): The specific X_train generated by 
                                the train_test_split function. 
                                
    Returns:
        list(int): The specific individual generated by the building a
                   list of integers are either 1 or 0
                   
    Example:
        >>> generate_individual(X_train)
        [ 1, 0, 1, 1, 1, ...]'''
    return [random.randint(0, 1) for x in range(len(X_train.columns))]


def fitness(individual, train_set, test_set):
    """Function that outputs the error rate given a train and 
    test set.
    
    The function takes an individual, a train set, and a test 
    set. The individual is comprised of a list of len(train_set)
    that contains either 0 or 1. 0 or 1 corresponds to whether 
    that specific column should be used. The train set and test 
    set are used to fit and predict the values in the test set
    
    Args:
        individual (list(int)): The specific individual thats a list comprised of 1s or 0s
        train_set (pd.DataFrame): The dataframe containg the test set
        test_set (pd.DataFrame): The dataframe contain the train set
        
    Returns:
        double: The error rate give the columns passed by the individual
        
    Example:
        >>> individual = [random.randint(0, 1) for x in len(X_train.columns)]
        >>> fitness(individual, (X_train, y_train), (X_test, y_test))
        0.30
        
    """
    
    X_train, y_train, X_test, y_test = parse_df_via_individual(individual, train_set, test_set)
    
    if len(X_train.columns) == 0:    
        return 1.0
    
    X_train, X_test = scale(X_train), scale(X_test)
    
    clf = svm.SVC()
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    error = mean_squared_error(y_true=y_test, y_pred=y_pred)
    total_correlation = calculate_correlation(X_train)
    
    return error * total_correlation


def main():

    random.seed(42)

    
    # create an initial population of 300 individuals (where
    # each individual is a list of integers)
    pop = toolbox.population(n=50)
    #print(pop)

    # CXPB  is the probability with which two individuals
    #       are crossed
    #
    # MUTPB is the probability for mutating an individual
    
    toolbox.register("evaluate", fitness_evaluate)
    toolbox.register("select", tools.selTournament, tournsize=3)
    toolbox.register("mate", tools.cxOrdered)
    toolbox.register("mutate", tools.mutShuffleIndexes, indpb=0.05)

    CXPB, MUTPB = 0.5, 0.4
    
    print("Start of evolution")

    f1=open("Meenakshi_Anbukkarasu_GA_TS_Info.txt","w+")
    
    # Evaluate the entire population
    fitnesses = list(map(toolbox.evaluate, pop,(X_train, y_train), (X_test, y_test)))


    for ind, fit in zip(pop, fitnesses):
        ind.fitness.values = fit
    
    print("Populaton size %i individuals\r\n" % len(pop))

    

    # Extracting all the fitnesses of 
    fits = [ind.fitness.values[0] for ind in pop]

    # Variable keeping track of the number of generations
    gen = 0

    # Begin the evolution
    while gen < 100 and min(fits)>10000:
        # A new generation
        gen = gen + 1

        #f1.write("Populaton Size: %i " % len(pop))       
        print("-- Generation %i --\r\n" % gen)
        
        # Select the next generation individuals
        offspring = toolbox.select(pop, len(pop))
        # Clone the selected individuals
        #subset=len(offspring)

        offspring = list(map(toolbox.clone, offspring))
    
        # Apply crossover and mutation on the offspring
        for child1, child2 in zip(offspring[::2], offspring[1::2]):

            # cross two individuals with probability CXPB
            if random.random() < CXPB:
                toolbox.mate(child1, child2)

                # fitness values of the children
                # must be recalculated later
                del child1.fitness.values
                del child2.fitness.values

        for mutant in offspring:

            # mutate an individual with probability MUTPB
            if random.random() < MUTPB:
                toolbox.mutate(mutant)
                del mutant.fitness.values
    
        # Evaluate the individuals with an invalid fitness
        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
        fitnesses = map(toolbox.evaluate, invalid_ind,(X_train, y_train), (X_test, y_test))
        for ind, fit in zip(invalid_ind, fitnesses):
            ind.fitness.values = fit
        
        #f1.write("  Evaluated %i individuals\r\n" % len(invalid_ind))
        # The population is entirely replaced by the offspring
        pop[:] = offspring

        subset = len(invalid_ind)
        
        # Gather all the fitnesses in one list and print the stats
        fits = [ind.fitness.values[0] for ind in pop]
        
      
        
    
    print("-- End of (successful) evolution --")
    
    best_ind = tools.selBest(pop, 1)[0]
    print("Best individual is %s with Fitness %s" % (best_ind, best_ind.fitness.values))

    f1.close()



if __name__ == "__main__":
    main()
